# Gunjan Voice Assistant

A **fully offline** voice assistant powered by **Qwen2.5-3B-Instruct-Q4_K_M** (GGUF), **Whisper** transcription, **gTTS** speech synthesis, and **FastAPI** web interface. **Single-turn responses** like Alexa with clean logging and background model loading.

## âœ¨ Features

- **Fully Offline LLM**: Gemma-2-2B-IT Q4_K_M (~1.4GB GGUF)
- **Whisper STT**: `openai/whisper-base.en` for accurate transcription
- **gTTS TTS**: Google Text-to-Speech â†’ MP3 playback
- **FastAPI Web UI**: `http://localhost:8000` with real-time health checks
- **Background Loading**: Instant server startup, model loads async
- **Structured Logging**: File rotation + terminal output
- **Single-Turn Mode**: Clean Alexa-style responses (no conversation memory)

## ğŸ› ï¸ Quick Start

### 1. Setup Environment
```bash
cd VoiceBot
python -m venv venv
source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
```

### 2. Download Model (~1.4GB)
```bash
mkdir -p models
wget -O models/gemma-2-2b-it-Q4_K_M.gguf \
  "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q4_K_M.gguf"
```

### 3. Audio Dependencies (Ubuntu)
```bash
sudo apt update && sudo apt install -y portaudio19-dev ffmpeg
pip install pyaudio
```

### 4. Run Server
```bash
python server.py
```
**Open:** `http://localhost:8000`  
**Wait:** Model loads in background (~1-2 min)  
**Status:** Check `/health` endpoint

## ğŸ“ Project Structure
```
â”œâ”€â”€ server.py              # FastAPI server + background model loading
â”œâ”€â”€ Voice_assistent.py     # VoiceChatbot class (Whisper + Gemma + gTTS)
â”œâ”€â”€ logger_config.py       # Structured logging (file + terminal)
â”œâ”€â”€ templates/index.html   # Web UI
â”œâ”€â”€ static/css/styles.css  # Responsive UI
â”œâ”€â”€ static/js/script.js    # MediaRecorder + API calls
â”œâ”€â”€ models/                # GGUF model (~1.4GB)
â”œâ”€â”€ uploads/               # Temp audio files (auto-cleaned)
â””â”€â”€ logs/                  # Rotated logs (Voicebot.log.*)
```

## ğŸš€ API Endpoints

| Method | Endpoint              | Description                  |
|--------|----------------------|------------------------------|
| `GET`  | `/`                  | Web UI                      |
| `GET`  | `/health`            | Model status (`model_loaded`) |
| `POST` | `/process_audio`     | Audio file â†’ transcription  |
| `POST` | `/get_response`      | Text â†’ single-turn LLM      |
| `POST` | `/synthesize_speech` | Text â†’ MP3 filename         |
| `GET`  | `/audio/{filename}`  | Serve TTS MP3               |

## ğŸ“¦ Requirements
```txt
fastapi
uvicorn[standard]
python-multipart
jinja2
pydantic
torch
transformers
langchain-community
llama-cpp-python
speechrecognition
pydub
gtts
python-dotenv
```

**Install:** `pip install -r requirements.txt`

## ğŸµ Workflow

```
ğŸ™ï¸ Record (WebM) â†’ WAV conversion â†’ Whisper STT
         â†“
     "Hello Gunjan" â†’ Gemma-2-2B â†’ "Okay I'm doing great!"
         â†“
     gTTS â†’ MP3 â†’ Browser playback
```

## âš™ï¸ Logging

**Terminal + File** (`logs/Voicebot.log`):
```
21:34:56,123 server.py [MainThread] - INFO  :  89 - âœ… Audio saved: user_audio_xyz.webm
21:34:57,456 server.py [MainThread] - INFO  : 102 - âœ… Transcribed: 'hello gunjan'
21:34:58,789 server.py [MainThread] - INFO  : 145 - Gunjan: Okay I'm doing great thanks!
```

**Monitor:** `tail -f logs/Voicebot.log`

## ğŸ”§ Troubleshooting

| Issue | Solution |
|-------|----------|
| `422 Unprocessable Entity` | `pip install python-multipart` |
| `No speech detected` | Check WAV conversion in `/process_audio` |
| `Model still loading` | Wait 1-2 min, check `/health` |
| Uvicorn spam | Add `logging.getLogger("uvicorn").setLevel(logging.WARNING)` |
| PyAudio fails | `sudo apt install portaudio19-dev` |

## ğŸ“± Web UI Features

- **Responsive design** (mobile + desktop)
- **Real-time health** (`/health` polling)
- **MediaRecorder API** (WebM â†’ Whisper)
- **Visual feedback** (recording pulse, status colors)
- **Error handling** (network, autoplay, transcription)

## ğŸš€ Production

```bash
# No reload for model stability
uvicorn server:app --host 0.0.0.0 --port 8000 --reload=False --log-level warning
```

## ğŸ’» Development Commands

```bash
# Clean logs
python -c "from logger_config import delete_old_logs; delete_old_logs('logs')"

# Test endpoints
curl -X POST -F "file=@test.wav" http://localhost:8000/process_audio

# Health check
curl http://localhost:8000/health
```

## ğŸ“ˆ Performance (CPU)

- **Server startup**: <1s (model loads async)
- **Model load**: 30-120s (Gemma-2-2B Q4_K_M)
- **STT**: 2-5s (Whisper base)
- **LLM**: 3-8s (single-turn, 100 tokens)
- **TTS**: 1-2s
- **RAM**: 4-6GB peak

## ğŸ¤ License
MIT License

***

**Gunjan - Your offline voice companion** ğŸ™ï¸ğŸš€