{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad8f050-9c46-4a96-8321-44f9b01431f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35487d13-a51d-4555-a727-d8476c90c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama \n",
    "\n",
    "llm = ChatOllama(\n",
    "    model= \"llama3.1:8b\", \n",
    "    temperature=0  # Low temp for reliable tool calling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3dd2f9-fe7b-4c92-bbe1-7c90aaf70577",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Add a and b.\n",
    "    \n",
    "    Args:\n",
    "        a (int): first integer to be added\n",
    "        b (int): second integer to be added\n",
    "\n",
    "    Return:\n",
    "        int: sum of a and b\n",
    "    \"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096cc3c0-2d39-486a-ad47-1b05d6f176dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011c32c4-5859-4b6c-bba9-abbe593f68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def subtract(a: int, b:int) -> int:\n",
    "    \"\"\"Subtract b from a.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b:int) -> int:\n",
    "    \"\"\"Multiply a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b:int) -> int:\n",
    "    \"\"\"divide a by b.\"\"\"\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df087d96-d911-4ba3-b109-0e60a86c1b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_map = {\n",
    "    \"add\": add, \n",
    "    \"subtract\": subtract,\n",
    "    \"multiply\": multiply,\n",
    "    \"divide\":divide\n",
    "}\n",
    "\n",
    "input_ = {\n",
    "    \"a\": 1,\n",
    "    \"b\": 2\n",
    "}\n",
    "\n",
    "tool_map[\"divide\"].invoke(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6996840c-1633-4fac-bf35-e1649fe943d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, subtract, multiply, divide]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad6e5f05-6219-4ab2-bd2e-f9ea9969b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 3 + 2?\"\n",
    "chat_history = [HumanMessage(content=query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "649b9cfc-e01e-4419-9bbb-97f4fde35b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5834b1-d403-4475-9bba-53cd24d06b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fe756d-4ca5-4c4f-8e4d-9a9bb79f505f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2026-01-17T16:39:57.053960589Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18852935266, 'load_duration': 10049017186, 'prompt_eval_count': 343, 'prompt_eval_duration': 4807006353, 'eval_count': 22, 'eval_duration': 3871047379, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019bccd3-99d6-7c21-a0e0-c2c8c3acc48a-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 2}, 'id': 'b57fb8fe-d70d-4dce-82b1-6c460560d031', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 343, 'output_tokens': 22, 'total_tokens': 365})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26434218-fd46-4cf4-8628-2ec13df823aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool name:\n",
      "add\n",
      "tool args:\n",
      "{'a': 3, 'b': 2}\n",
      "tool call ID:\n",
      "b57fb8fe-d70d-4dce-82b1-6c460560d031\n"
     ]
    }
   ],
   "source": [
    "tool_calls_1 = response_1.tool_calls\n",
    "\n",
    "tool_1_name = tool_calls_1[0][\"name\"]\n",
    "tool_1_args = tool_calls_1[0][\"args\"]\n",
    "tool_call_1_id = tool_calls_1[0][\"id\"]\n",
    "\n",
    "print(f'tool name:\\n{tool_1_name}')\n",
    "print(f'tool args:\\n{tool_1_args}')\n",
    "print(f'tool call ID:\\n{tool_call_1_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44cd3e33-bf24-4b7f-9411-bb40c53652c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='5', tool_call_id='b57fb8fe-d70d-4dce-82b1-6c460560d031')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_response = tool_map[tool_1_name].invoke(tool_1_args)\n",
    "tool_message = ToolMessage(content=tool_response, tool_call_id=tool_call_1_id)\n",
    "\n",
    "tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "910ac8fe-103f-402b-8843-73991d3ab989",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab4e2c0a-2c3d-40a2-af15-8434444c9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm_with_tools.invoke(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0b63681-1cbc-4766-94cb-c45345db2918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "The answer to the equation 3 + 2 is 5.\n"
     ]
    }
   ],
   "source": [
    "print(type(answer))\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d566730f-4f05-4234-ad04-a5a6f2edeee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCallingAgent:\n",
    "    def __init__(self, llm, tools):\n",
    "        self.llm_with_tools = llm.bind_tools(tools)\n",
    "        self.tool_map = tool_map\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        # Step 1: Initial user message\n",
    "        chat_history = [HumanMessage(content=query)]\n",
    "\n",
    "        # Step 2: LLM chooses tool\n",
    "        response = self.llm_with_tools.invoke(chat_history)\n",
    "        if not response.tool_calls:\n",
    "            return response.contet # Direct response, no tool needed\n",
    "        # Step 3: Handle first tool call\n",
    "        tool_call = response.tool_calls[0]\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        tool_call_id = tool_call[\"id\"]\n",
    "\n",
    "        # Step 4: Call tool manually\n",
    "        tool_result = self.tool_map[tool_name].invoke(tool_args)\n",
    "\n",
    "        # Step 5: Send result back to LLM\n",
    "        tool_message = ToolMessage(content=str(tool_result), tool_call_id=tool_call_id)\n",
    "        chat_history.extend([response, tool_message])\n",
    "\n",
    "        # Step 6: Final LLM result\n",
    "        final_response = self.llm_with_tools.invoke(chat_history)\n",
    "        return final_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "006d89e5-204c-4b3c-8805-b128070a46ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of one plus two is three.\n",
      "The result of 2 minus 1 is 1.\n",
      "The result of multiplying 3 by 2 is 6.\n",
      "The result of dividing 8 by 4 is 2.\n"
     ]
    }
   ],
   "source": [
    "my_agent = ToolCallingAgent(llm, tools)\n",
    "\n",
    "print(my_agent.run(\"one plus 2\"))\n",
    "\n",
    "print(my_agent.run(\"two minus one\"))\n",
    "\n",
    "print(my_agent.run(\"three times two\"))\n",
    "\n",
    "print(my_agent.run(\"eight divided by 4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc45ca06-c62a-4ce5-9913-515978d1fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate_tip(total_bill: int, tip_percent: int) -> int:\n",
    "    \"\"\"Calculate tip\"\"\"\n",
    "    return total_bill * tip_percent * 0.01\n",
    "\n",
    "inputs = {\n",
    "    \"total_bill\": 120,\n",
    "    \"tip_percent\": 15\n",
    "}\n",
    "calculate_tip.invoke(inputs)\n",
    "\n",
    "\n",
    "tool_map = {\n",
    "    \"calculate_tip\": calculate_tip\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f56d881-77b9-4bed-b349-400cca092fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount you should tip is $12.00.\n"
     ]
    }
   ],
   "source": [
    "query = \"How much should I tip on $60 at 20%?\"\n",
    "\n",
    "llm_with_tool = llm.bind_tools([calculate_tip])\n",
    "chat_history = [HumanMessage(content=query)]\n",
    "\n",
    "response = llm_with_tool.invoke(chat_history)\n",
    "\n",
    "tool_calls = response.tool_calls\n",
    "tool_name = tool_calls[0][\"name\"]\n",
    "tool_args = tool_calls[0][\"args\"]\n",
    "tool_call_id = tool_calls[0][\"id\"]\n",
    "\n",
    "tool_response = tool_map[tool_name].invoke(tool_args)\n",
    "tool_message = ToolMessage(content=tool_response, tool_call_id=tool_call_id)\n",
    "\n",
    "chat_history.extend([response, tool_message])\n",
    "\n",
    "result = llm_with_tool.invoke(chat_history)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c20121d-8728-4f52-bb4f-bf3d59c5f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TipAgent:\n",
    "    def __init__(self, llm, tools):\n",
    "        self.llm_with_tool = llm.bind_tools(tools)\n",
    "        self.tool_map = tool_map\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        chat_history = [HumanMessage(content=query)]\n",
    "        response = llm_with_tool.invoke(chat_history)\n",
    "\n",
    "        tool_calls = response.tool_calls\n",
    "        tool_name = tool_calls[0][\"name\"]\n",
    "        tool_args = tool_calls[0][\"args\"]\n",
    "        tool_call_id = tool_calls[0][\"id\"]\n",
    "        \n",
    "        tool_response = tool_map[tool_name].invoke(tool_args)\n",
    "        tool_message = ToolMessage(content=tool_response, tool_call_id=tool_call_id)\n",
    "        \n",
    "        chat_history.extend([response, tool_message])\n",
    "        \n",
    "        return llm_with_tool.invoke(chat_history).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd48b816-6c80-403b-8366-7e318fa2dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [calculate_tip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c64e687-ba92-4bfb-9689-e2afac9bf3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The tip for a $900 bill at 20% would be $180.00.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = TipAgent(llm, tools)\n",
    "query = \"How much should I tip on 900 at 20%?\"\n",
    "\n",
    "agent.run(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
