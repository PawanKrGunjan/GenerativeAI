# ğŸ¤– AI Meeting Assistant

A **local, CPU-only AI Meeting Assistant** that transcribes meeting audio, normalizes financial terminology, and generates **professional meeting minutes with task assignments** â€” no cloud APIs, no keys required.

Powered by **Ollama (Qwen 2.5 3B)** and **Whisper Speech-to-Text**.

---

## âœ¨ Features

- ğŸ™ **Speech-to-Text** using OpenAI Whisper (CPU-optimized)
- ğŸ’° **Financial Term Normalization**
  - Expands acronyms (ROA â†’ Return on Assets (ROA))
  - Converts spoken numbers (four zero one k â†’ 401(k) Retirement Savings Plan)
  - Context-aware disambiguation (LTV, EBITDA, etc.)
- ğŸ“ **Structured Meeting Minutes**
  - Key discussion points
  - Decisions made
  - Task assignments table (assignee, deadline, priority)
- ğŸ“„ **Markdown Export**
- ğŸ–¥ **Fully Local**
  - No IBM Watsonx
  - No OpenAI API
  - No internet required after model download
- âš™ï¸ **CPU-only friendly** (8 GB RAM supported)

---

## ğŸ§± Architecture

```text
Audio File
   â”‚
   â–¼
Whisper STT (local, CPU)
   â”‚
   â–¼
Financial Terminology Normalizer (LLM)
   â”‚
   â–¼
Meeting Intelligence Generator (LLM)
   â”‚
   â–¼
Markdown Report + Download
````

---

## ğŸ“¦ Requirements

### System

* Linux / macOS / Windows
* Python **3.9+**
* **8 GB RAM** recommended
* CPU-only (GPU optional but not required)

### Software

* Ollama (running locally)

---

## ğŸ”§ Installation

### 1ï¸âƒ£ Install Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### 2ï¸âƒ£ Pull Required Models

```bash
ollama pull qwen2.5:3b
```

(Whisper models are downloaded automatically by Transformers.)

---

### 3ï¸âƒ£ Create Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 4ï¸âƒ£ Install Dependencies

```bash
pip install -U \
  torch \
  gradio>=4.0 \
  transformers \
  langchain-core \
  langchain-ollama
```

---

## âš™ï¸ Environment Configuration (IMPORTANT)

For **CPU-only and low-memory systems**, set the following environment variables **before running the app**:

```bash
export OLLAMA_NUM_PARALLEL=1
export OLLAMA_MAX_LOADED_MODELS=1
export TOKENIZERS_PARALLELISM=false
```

### Why this matters

* Prevents Ollama from loading multiple models simultaneously
* Reduces RAM pressure and swap usage
* Avoids tokenizer thread over-subscription
* Improves stability on 8 GB systems

Optional (Linux only):

```bash
sudo sysctl vm.swappiness=10
```

---

## ğŸš€ Running the Application

```bash
python speech_analyzer.py
```

Then open your browser at:

```
http://localhost:5000
```

---

## ğŸ§ Supported Audio Formats

* MP3
* WAV
* M4A
* FLAC

**Recommended:**

* Mono audio
* â‰¤ 30 minutes for best CPU performance

---

## ğŸ“„ Output

* On-screen **Markdown-formatted meeting minutes**
* Downloadable `.md` file stored in:

  ```text
  outputs/meeting_minutes_<audio_name>.md
  ```

---

## ğŸ§  Model Choices

### LLM (Ollama)

| Model         | Use Case                            |
| ------------- | ----------------------------------- |
| `qwen2.5:3b`  | âœ… Best balance of reasoning & speed |
| `llama3.2:1b` | Low-RAM fallback                    |

### Speech-to-Text

| Model            | RAM   | Accuracy        |
| ---------------- | ----- | --------------- |
| `whisper-tiny`   | ~1 GB | Fast            |
| `whisper-small`  | ~2 GB | â­ Recommended   |
| `whisper-medium` | ~5 GB | Best (slow CPU) |

---

## ğŸ›  Troubleshooting

### âŒ Whisper Long-Audio Error

> You have passed more than 3000 mel input featuresâ€¦

âœ… **Solution:**
The app enables `return_timestamps=True`, which is required for long-form Whisper transcription.

---

### âŒ Ollama Not Responding

```bash
ollama ps
```

Ensure `qwen2.5:3b` is running.

---

## ğŸ”’ Privacy

* All processing is **local**
* No data leaves your machine
* Suitable for confidential meetings

---

## ğŸ§© Project Structure

```text
.
â”œâ”€â”€ speech_analyzer.py
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ meeting_minutes_*.md
â”œâ”€â”€ README.md
â””â”€â”€ venv/
```

---

## ğŸ›£ Roadmap (Optional Enhancements)

* Speaker diarization
* RAG over past meetings
* JSON / Pydantic outputs
* OpenVINO-accelerated Whisper
* FastAPI backend
* Streaming transcription

---

## ğŸ“œ License

MIT License â€” free to use, modify, and distribute.

---

## ğŸ™Œ Acknowledgements

* Ollama
* LangChain
* Hugging Face Transformers
* OpenAI Whisper

```

