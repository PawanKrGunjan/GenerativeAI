---

## **1. What is Generative AI?**

**Answer:**
Generative AI refers to models that can **create new content**—text, images, audio, code, simulations—based on patterns learned from training data. Unlike discriminative models, which classify or predict labels, generative models learn the **underlying distribution** of data and can sample from it to produce novel outputs. Examples include GPT, DALL·E, Stable Diffusion, and MusicLM.

---

## **2. How does a Large Language Model (LLM) work?**

**Answer:**
LLMs are built on transformer architectures, which rely on:

* **Self-attention** to understand relationships between tokens
* **Positional encoding** to capture word order
* **Dense layers** to transform representations
  During training, they predict the next token in a sequence (causal modeling), gradually learning grammar, reasoning patterns, and world knowledge from massive text corpora.

---

## **3. What is the Transformer architecture?**

**Answer:**
A transformer is a deep learning model that uses **attention mechanisms** instead of recurrence. Its key components are:

* **Multi-Head Self-Attention**
* **Feedforward neural networks**
* **Layer normalization**
* **Residual connections**
  Transformers process tokens **in parallel**, making them highly scalable and efficient for large-scale language models.

---

## **4. What is “attention” in the context of transformers?**

**Answer:**
Attention is a mechanism that determines **how much focus** the model should assign to each input token when generating an output.
Formula:
**Attention(Q, K, V) = softmax(QKᵀ / √dₖ) × V**
This allows the model to capture context, relationships, dependencies, and long-range patterns.

---

## **5. What is the difference between Generative AI and Traditional ML?**

**Answer:**

* **Traditional ML:** Predicts labels or numerical outputs; works on structured tasks.
* **Generative AI:** Creates new content; learns data distributions and outputs sequences, images, etc.
  Generative AI also requires significantly larger datasets and computational resources.

---

## **6. What is the difference between GPT and BERT?**

**Answer:**

| Feature      | GPT                                 | BERT                       |
| ------------ | ----------------------------------- | -------------------------- |
| Training     | Autoregressive (predict next token) | Autoencoding (mask tokens) |
| Direction    | Left → Right                        | Bidirectional              |
| Usage        | Text generation                     | Classification, embeddings |
| Output Style | Generative                          | Discriminative             |

---

## **7. What is a token?**

**Answer:**
A token is a **unit of text** used by LLMs—typically a word, subword, or character. Tokenizers (like BPE or WordPiece) break text into tokens the model can process. LLM billing, context length, and input/output size are measured in tokens.

---

## **8. What is “context length”?**

**Answer:**
Context length is the **maximum number of tokens** an LLM can consider in one input.
Larger context windows allow:

* Better recall of long conversations
* More complex reasoning
* Full-document understanding

---

## **9. What is fine-tuning?**

**Answer:**
Fine-tuning updates a pre-trained model’s weights using domain-specific data. Types include:

* **Full fine-tuning** – adjusts all parameters
* **LoRA / PEFT** – updates small low-rank matrices
* **Instruction tuning** – improves task-following behavior

Fine-tuning enables specialization without training from scratch.

---

## **10. What is Prompt Engineering?**

**Answer:**
Prompt engineering is designing structured instructions that guide LLM behavior. Techniques include:

* Role-based prompting
* Few-shot prompting
* Chain-of-thought reasoning
* Guardrails and constraints
* Output formatting instructions

---

## **11. What is Retrieval-Augmented Generation (RAG)?**

**Answer:**
RAG combines a **retriever** (like vector search) with a **generator** (LLM).
Process:

1. Convert documents into embeddings
2. Retrieve relevant chunks
3. Feed retrieved text into the LLM
   RAG improves accuracy, reduces hallucinations, and enables enterprise knowledge integration.

---

## **12. What are hallucinations in LLMs?**

**Answer:**
Hallucinations occur when models **produce confident but incorrect or fabricated information**. They arise due to:

* Missing retrieval context
* Ambiguous prompts
* Over-generalization
* Model trying to satisfy patterns even without facts

Mitigation includes grounding, RAG, verification, and model constraints.

---

## **13. What is a diffusion model?**

**Answer:**
Diffusion models generate images by:

1. **Adding noise** to an image until it becomes pure noise
2. **Learning to reverse the noising process**
3. Gradually de-noising to create a new image following the learned distribution
   Stable Diffusion and Imagen use this technique.

---

## **14. What are embeddings?**

**Answer:**
Embeddings are **dense vector representations** of text, images, or items. They encode meaning so that similar concepts appear near each other in vector space. Used for:

* Semantic search
* Clustering
* RAG retrieval
* Recommendation systems

---

## **15. What is temperature in text generation?**

**Answer:**
Temperature controls randomness:

* **Low temperature (0–0.3):** Deterministic, factual
* **Medium (0.5–0.7):** Balanced
* **High (0.8–1.5):** Creative, unpredictable

---

## **16. What are top-k and top-p sampling?**

**Answer:**

* **Top-k:** Selects the next token from the top *k* most likely tokens.
* **Top-p (nucleus sampling):** Selects from the smallest set of tokens whose cumulative probability ≥ *p*.
  Both help balance creativity and coherence.

---

## **17. What is instruction tuning?**

**Answer:**
Instruction tuning trains models on datasets of **task instructions + desired responses**. This makes models more aligned with user intent and better at following commands.

---

## **18. What is RLHF (Reinforcement Learning from Human Feedback)?**

**Answer:**
RLHF uses human feedback to refine model behavior. Process:

1. **Pretrain** on large text
2. **Supervised fine-tune** on chosen examples
3. **Train reward model** using human-ranked outputs
4. **Optimize with reinforcement learning**

This makes models safer and more helpful.

---

## **19. What is chain-of-thought reasoning?**

**Answer:**
Chain-of-thought (CoT) prompting instructs the model to **show intermediate reasoning steps**, improving performance on:

* Logic tasks
* Math
* Multi-step reasoning

Example: “Let’s think this through step by step.”

---

## **20. What are guardrails in GenAI systems?**

**Answer:**
Guardrails are safety layers that filter and shape model behavior. They handle:

* Harmful content
* Privacy protection
* Policy compliance
* Prompt filtering
* Output validation

Tools include LLM wrappers, rule-based engines, and moderation models.

---

## **21. What is the difference between training and inference?**

**Answer:**

* **Training:**

  * Computationally expensive
  * Updates model weights
  * Requires huge datasets

* **Inference:**

  * Applying the trained model to new prompts
  * Fast and optimized
  * Uses pre-trained weights

---

## **22. What factors influence LLM performance?**

1. Model size
2. Training data quality
3. Tokenizer type
4. Context window
5. Fine-tuning or instruction tuning
6. Hardware & parallelism
7. Sampling parameters (temperature, top-p)

---

## **23. What is model drift in Generative AI?**

**Answer:**
Model drift occurs when an LLM’s outputs become **less accurate over time** due to changing facts, user behavior, or real-world knowledge.
Mitigation includes:

* Continuous RAG updates
* Periodic fine-tuning
* Monitoring feedback loops

---

## **24. What privacy concerns exist with Generative AI?**

**Answer:**

* Leakage of sensitive data
* Memorization of training examples
* Prompt injection attacks
* Unauthorized content generation

Organizations mitigate risk through differential privacy, model redaction, encryption, and secure deployments.

---

## **25. How do you evaluate Generative AI outputs?**

Evaluation dimensions include:

* **Relevance**
* **Accuracy / factuality**
* **Hallucination rate**
* **Coherence**
* **Safety compliance**
* **Human preference metrics**
* **BLEU / ROUGE / METEOR** for text
* **FID / IS** for images

Human evaluation remains essential for many tasks.

