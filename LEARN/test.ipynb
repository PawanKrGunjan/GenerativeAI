{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ae5bb2-0337-44f4-96ae-af33c5836cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class WeatherSchema(BaseModel):\n",
    "    condition: str = Field(description=\"Weather condition such as sunny, rainy, cloudy\")\n",
    "    temperature: int = Field(description=\"Temperature value\")\n",
    "    unit: str = Field(description=\"Temperature unit such as fahrenheit or celsius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f6e4c-21a0-4805-911e-1f3e85c35b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create an LLM instance\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")  # or your preferred model\n",
    "\n",
    "weather_llm = llm.bind_tools(tools=[WeatherSchema])\n",
    "response = weather_llm.invoke(\"It's sunny and 75 degrees\")\n",
    "# Returns: {\"condition\": \"sunny\", \"temperature\": 75, \"unit\": \"fahrenheit\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32eefd8-716e-4366-bfd3-f61a2d0d58d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mphi3:mini\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Instantiate the LLM with the specified model\u001b[39;00m\n\u001b[32m      7\u001b[39m llm = OllamaLLM(\n\u001b[32m      8\u001b[39m     model=model_name,\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     temperature=\u001b[43mdefault_params\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     10\u001b[39m     top_p=default_params[\u001b[33m'\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     11\u001b[39m     top_k=default_params[\u001b[33m'\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     12\u001b[39m     repeat_penalty=default_params[\u001b[33m'\u001b[39m\u001b[33mrepetition_penalty\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     13\u001b[39m     num_predict=default_params[\u001b[33m'\u001b[39m\u001b[33mmax_new_tokens\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     14\u001b[39m     seed=default_params[\u001b[33m'\u001b[39m\u001b[33mrandom_seed\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     15\u001b[39m     stop=default_params[\u001b[33m'\u001b[39m\u001b[33mstop_sequences\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'default_params' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Use a valid model name that Ollama is serving locally.\n",
    "model_name = \"phi3:mini\"\n",
    "\n",
    "# Instantiate the LLM with the specified model\n",
    "llm = OllamaLLM(\n",
    "    model=model_name,\n",
    "    temperature=default_params['temperature'],\n",
    "    top_p=default_params['top_p'],\n",
    "    top_k=default_params['top_k'],\n",
    "    repeat_penalty=default_params['repetition_penalty'],\n",
    "    num_predict=default_params['max_new_tokens'],\n",
    "    seed=default_params['random_seed'],\n",
    "    stop=default_params['stop_sequences'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6737550d-d0c8-45aa-9faf-83f4f2b739e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244da205-10c4-46c9-8f18-be89d7a45f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
