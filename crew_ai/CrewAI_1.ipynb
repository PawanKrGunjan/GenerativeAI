{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6976ccab-80a0-4bfc-9760-95735e7df95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1b8e42-0ce2-42eb-bbf0-15899398434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'crewai_tools.tools.serper_dev_tool.serper_dev_tool.SerperDevTool'>\n"
     ]
    }
   ],
   "source": [
    "from crewai_tools import SerperDevTool\n",
    "#os.environ['SERPER_API_KEY']\n",
    "search_tool=SerperDevTool()\n",
    "print(type(search_tool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a937aea-d3e1-401c-b5a0-b2e3a1ccbf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mUsing Tool: Search the internet with Serper\u001b[0m\n",
      "Search Results for 'What is the key feature of CrewAI agent collaborations?':\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'searchParameters': {'q': 'What is the key feature of CrewAI agent collaborations?',\n",
       "  'type': 'search',\n",
       "  'num': 10,\n",
       "  'engine': 'google'},\n",
       " 'organic': [{'title': 'Collaboration',\n",
       "   'link': 'https://docs.crewai.com/en/concepts/collaboration',\n",
       "   'snippet': \"Collaboration in CrewAI enables agents to work together as a team by delegating tasks and asking questions to leverage each other's expertise.\",\n",
       "   'position': 1},\n",
       "  {'title': 'What is Crew AI: Collaborative Autonomous Agent ...',\n",
       "   'link': 'https://medium.com/@tahirbalarabe2/what-is-crew-ai-collaborative-autonomous-agent-framework-cbffc7926e1b',\n",
       "   'snippet': 'Key Features · Role-Based Design Each agent has a defined role, like “coder” or “tester,” with tailored tools and objectives. · Tool Integration',\n",
       "   'position': 2},\n",
       "  {'title': 'What is crewAI?',\n",
       "   'link': 'https://www.ibm.com/think/topics/crew-ai',\n",
       "   'snippet': \"Agents engage with one another through crewAI's inherent delegation and communication mechanisms giving them the innate ability to reach out to one another to ...\",\n",
       "   'position': 3},\n",
       "  {'title': 'Exploring crewAI: The Future of Multi-Agent Collaboration',\n",
       "   'link': 'https://www.keywordsearch.com/blog/exploring-crewai-future-of-multi-agent-collaboration',\n",
       "   'snippet': 'CrewAI is an open-source framework that facilitates multi-agent collaboration, allowing teams of AI agents to work together on complex tasks ...',\n",
       "   'position': 4},\n",
       "  {'title': 'Crewai:Collaboration',\n",
       "   'link': 'https://crewai.net/posts/crewai-collaboration/',\n",
       "   'snippet': 'CrewAI revolutionizes AI collaboration, enabling agents to share information, assist in tasks, and optimize resources through advanced ...',\n",
       "   'position': 5},\n",
       "  {'title': 'CrewAI - AWS Prescriptive Guidance',\n",
       "   'link': 'https://docs.aws.amazon.com/prescriptive-guidance/latest/agentic-ai-frameworks/crewai.html',\n",
       "   'snippet': 'Key features of CrewAI · Role-based agent design – Autonomous agents are defined with specific roles, goals, and back stories to enable specialized expertise.',\n",
       "   'position': 6},\n",
       "  {'title': 'Introduction',\n",
       "   'link': 'https://docs.crewai.com/en/introduction',\n",
       "   'snippet': 'Autonomous Collaboration: Agents work together to solve tasks. Task Delegation: Tasks are assigned and executed based on agent capabilities.',\n",
       "   'position': 7},\n",
       "  {'title': 'Comparing Agent Cloud and CrewAI : r/AutoGenAI',\n",
       "   'link': 'https://www.reddit.com/r/AutoGenAI/comments/1bzrxbv/comparing_agent_cloud_and_crewai/',\n",
       "   'snippet': \"Key Features of CrewAI: · Multi-Agent Collaboration: Multi-agent collaboration is the core of CrewAI's strength. · Role-Based Design: Assign ...\",\n",
       "   'position': 8},\n",
       "  {'title': 'How CrewAI Enables AI Agents as Collaborative Team ...',\n",
       "   'link': 'https://thenewstack.io/how-crewai-enables-ai-agents-as-collaborative-team-members/',\n",
       "   'snippet': 'CrewAI facilitates seamless multi-agent coordination by enabling agents to work collaboratively within structured workflows. Workflows can be ...',\n",
       "   'position': 9},\n",
       "  {'title': 'Day 66 – CrewAI: Multi-Agent Collaboration Simplified',\n",
       "   'link': 'https://www.linkedin.com/pulse/day-66-crewai-multi-agent-collaboration-simplified-sai-venkat-javvadi-lwtbc',\n",
       "   'snippet': 'Key Features of CrewAI · Role-Based Agents – Agents can be assigned unique skills and responsibilities (e.g., writer, fact-checker, coder).',\n",
       "   'position': 10}],\n",
       " 'credits': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query = \"What is the key feature of CrewAI agent collaborations?\"\n",
    "search_results =search_tool.run(query=search_query )\n",
    "\n",
    "# Print the results\n",
    "print(f\"Search Results for '{search_query}':\\n\")\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5e20f7-c2d7-403b-9b2f-324181479bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['searchParameters', 'organic', 'credits'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb9ac90-ee1f-430f-a2e9-5f1f4f947803",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Error importing native provider: OPENAI_API_KEY is required",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/G-master/lib/python3.12/site-packages/crewai/llm.py:404\u001b[39m, in \u001b[36mLLM.__new__\u001b[39m\u001b[34m(cls, model, is_litellm, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m     kwargs_copy = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33mprovider\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    403\u001b[39m         Self,\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m         \u001b[43mnative_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_copy\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    405\u001b[39m     )\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/G-master/lib/python3.12/site-packages/crewai/llms/providers/openai/completion.py:97\u001b[39m, in \u001b[36mOpenAICompletion.__init__\u001b[39m\u001b[34m(self, model, api_key, base_url, organization, project, timeout, max_retries, default_headers, default_query, client_params, temperature, top_p, frequency_penalty, presence_penalty, max_tokens, max_completion_tokens, seed, stream, response_format, logprobs, top_logprobs, reasoning_effort, provider, interceptor, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     88\u001b[39m     model=model,\n\u001b[32m     89\u001b[39m     temperature=temperature,\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m     **kwargs,\n\u001b[32m     95\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m client_config = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_client_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.interceptor:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/G-master/lib/python3.12/site-packages/crewai/llms/providers/openai/completion.py:134\u001b[39m, in \u001b[36mOpenAICompletion._get_client_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY is required\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m base_params = {\n\u001b[32m    137\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.api_key,\n\u001b[32m    138\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33morganization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.organization,\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdefault_query\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.default_query,\n\u001b[32m    148\u001b[39m }\n",
      "\u001b[31mValueError\u001b[39m: OPENAI_API_KEY is required",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcrewai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m perplexity_llm = \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msonar-pro\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://api.perplexity.ai/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m500\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/G-master/lib/python3.12/site-packages/crewai/llm.py:409\u001b[39m, in \u001b[36mLLM.__new__\u001b[39m\u001b[34m(cls, model, is_litellm, **kwargs)\u001b[39m\n\u001b[32m    407\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError importing native provider: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# FALLBACK to LiteLLM\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m LITELLM_AVAILABLE:\n",
      "\u001b[31mImportError\u001b[39m: Error importing native provider: OPENAI_API_KEY is required"
     ]
    }
   ],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "perplexity_llm = LLM(\n",
    "    model=\"sonar-pro\",\n",
    "    base_url=\"https://api.perplexity.ai/\",\n",
    "    max_tokens= 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d4c0c-79dc-4f05-b9b0-7493f62b9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_llm = LLM(\n",
    "    model=\"ollama/llama3.2:latest\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    max_tokens= 251\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cb8ca-eedb-4e53-b541-9391bdb6690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent\n",
    "\n",
    "research_agent = Agent(\n",
    "  role='Senior Research Analyst',\n",
    "  goal='Uncover cutting-edge information and insights on any subject with comprehensive analysis',\n",
    "  backstory=\"\"\"You are an expert researcher with extensive experience in gathering, analyzing, and synthesizing information across multiple domains. \n",
    "  Your analytical skills allow you to quickly identify key trends, separate fact from opinion, and produce insightful reports on any topic. \n",
    "  You excel at finding reliable sources and extracting valuable information efficiently.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  llm = perplexity_llm,\n",
    "  tools=[SerperDevTool()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4c980-1880-4b19-91bb-ccc6cf56c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbfe539-eace-4e91-aa12-92471b707eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your agents with roles and goals\n",
    "# Define the Writer Agent\n",
    "writer_agent = Agent(\n",
    "  role='Tech Content Strategist',\n",
    "  goal='Craft well-structured and engaging content based on research findings',\n",
    "  backstory=\"\"\"You are a skilled content strategist known for translating \n",
    "  complex topics into clear and compelling narratives. Your writing makes \n",
    "  information accessible and engaging for a wide audience.\"\"\",\n",
    "  verbose=True,\n",
    "  llm = perplexity_llm,\n",
    "  allow_delegation=True\n",
    ")\n",
    "\n",
    "writer_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee970974-da31-4f94-93c1-554483179629",
   "metadata": {},
   "source": [
    "## **Tasks in CrewAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959ecb0-b7b7-4b2f-bdfb-3f76b6c8a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task\n",
    "\n",
    "research_task = Task(\n",
    "  description=\"Analyze the major {topic}, identifying key trends and technologies. Provide a detailed report on their potential impact.\",\n",
    "  agent=research_agent,\n",
    "  expected_output=\"A detailed report on {topic}, including trends, emerging technologies, and their impact.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacf34e-7ec2-49bf-84f3-549013dbf22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a task for the Writer Agent\n",
    "writer_task = Task(\n",
    "  description=\"Create an engaging blog post based on the research findings about {topic}. Tailor the content for a tech-savvy audience, ensuring clarity and interest.\",\n",
    "  agent=writer_agent,\n",
    "  expected_output=\"A 4-paragraph blog post on {topic}, written clearly and engagingly for tech enthusiasts.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f292870d-3f4e-4dab-967d-73bfc8aaef7f",
   "metadata": {},
   "source": [
    "## CrewAI Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec05e3-d160-4eec-ab7f-2b4a0dc905b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[research_agent, writer_agent],\n",
    "    tasks=[research_task, writer_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f7ad5-0ddc-400c-ab75-3842fb580bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = crew.kickoff(inputs={\"topic\": \"Latest Generative AI breakthroughs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b325c-1f13-4e52-b727-56987e6816de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))\n",
    "dir(result)\n",
    "result.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7104ee-0438-4fbd-975c-7ae2c6f9211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.schema().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b66e3-698f-439e-96db-c6934b59cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_outputs = result.tasks_output\n",
    "\n",
    "print(\"Task Description\", tasks_outputs[0].description)\n",
    "print(\"*\"*75)\n",
    "print(\"Output of research task \",tasks_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba373502-cc8c-4d85-b0ed-11a16cd5b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writer task description:\", tasks_outputs[1].description)\n",
    "print(\"*\"*75)\n",
    "print(\" \\nOutput of writer task:\", tasks_outputs[1].raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd102f4-9ee0-4700-846e-2fc0b4cead64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We can get the agent for researcher task: \",tasks_outputs[0].agent)\n",
    "print(\"We can get the agent for the writer task: \",tasks_outputs[1].agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45d088-0283-4c15-850e-74487b5ac49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count = result.token_usage.total_tokens\n",
    "prompt_tokens = result.token_usage.prompt_tokens\n",
    "completion_tokens = result.token_usage.completion_tokens\n",
    "\n",
    "print(f\"Total tokens used: {token_count}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens} (used for instructions to the model)\")\n",
    "print(f\"Completion tokens: {completion_tokens} (generated in response)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf87a97-cd83-4c08-94f6-acf35dada52d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
