{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7c1233-5159-4562-8ce3-b45a233fb047",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc37ce4-46d0-4b17-80df-43e521e27dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 09:59:14.193074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f645b-ea77-4be0-b3d1-db479d57a609",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e66ad874-b455-4475-b581-2562523041a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity LLM ‚Äî Correct model name (December 2025)\n",
    "perplexity_llm = ChatOpenAI(\n",
    "    base_url=\"https://api.perplexity.ai\",\n",
    "    api_key=os.getenv(\"PERPLEXITY_API_KEY\"),\n",
    "    model=\"sonar-pro\",           # ‚Üê THIS IS THE CORRECT MODEL\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    temperature=0.3,\n",
    "    max_output_tokens=8192\n",
    ")\n",
    "\n",
    "ollama_llm = ChatOllama(\n",
    "    model = 'llama3.2:latest',\n",
    "    temperature=0.0,\n",
    "    max_output_tokens=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68d9607-6862-4e02-af7e-3520bf64fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(max_lokens=1000):\n",
    "    ollama_llm = ChatOllama(\n",
    "        model = 'llama3.2:latest',\n",
    "        temperature=0.0,\n",
    "        max_output_tokens=max_lokens\n",
    "    )\n",
    "    return ollama_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd59ca2-7fcf-411e-a3d2-b53d4fafcf5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf3dfcf-b88b-43d2-a0b7-bf8d6898f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW correct import (post LangChain 0.1+)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e3f0cb-981a-4fca-a941-d1312a85a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_splitter(data, chunk_size, chunk_overlap):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d124813e-61fc-4344-84d2-668f12e64349",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff063fd-ecd5-43ad-b592-4b6fa465cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Embeddings (most popular free alternative)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def openai_embedding():\n",
    "    return OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        dimensions=1536  # Match WatsonX vector size\n",
    "    )\n",
    "\n",
    "# Google Gemini Embeddings (your existing API key)\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "def gemini_embedding():\n",
    "    return GoogleGenerativeAIEmbeddings(\n",
    "        model=\"models/embedding-001\",\n",
    "        google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    "    )\n",
    "\n",
    "# Hugging Face (completely free, local)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def hf_embedding():\n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={'device': 'cpu'}  # or 'cuda'\n",
    "    )\n",
    "\n",
    "# Ollama (local, free)\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "def ollama_embedding():\n",
    "    return OllamaEmbeddings(\n",
    "        model=\"nomic-embed-text\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e52ce2-440b-43fc-b0b0-9ac997a74ea8",
   "metadata": {},
   "source": [
    "## Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ef144-b8b7-40c5-952c-ff3d619320e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Vector Store-Backed Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d6812a0-605f-4b57-8823-9e42e9756227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-10 09:59:17--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/MZ9z1lm-Ui3YBp3SYWLTAQ/companypolicies.txt\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15660 (15K) [text/plain]\n",
      "Saving to: ‚Äòcompanypolicies.txt.2‚Äô\n",
      "\n",
      "companypolicies.txt 100%[===================>]  15.29K  --.-KB/s    in 0s      \n",
      "\n",
      "2026-01-10 09:59:22 (179 MB/s) - ‚Äòcompanypolicies.txt.2‚Äô saved [15660/15660]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/MZ9z1lm-Ui3YBp3SYWLTAQ/companypolicies.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e39627-3506-45f8-b9af-dcbf53850565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044c1ca3-48be-4c0e-b5c1-964b1e2b9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"companypolicies.txt\")\n",
    "txt_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9e17cf4-bc59-4f50-bb77-f6d1dc53facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1627a9-ad83-473d-afae-4c7459ec76c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunks_txt = text_splitter(txt_data, 200, 25)\n",
    "#hunks_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a19340-cb2b-4aa4-8e00-69480e546545",
   "metadata": {},
   "source": [
    "#### Store the embeddings into a `ChromaDB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14c68fb0-8d27-4106-9073-c5be6c9cbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "#from `langchain_chroma import Chroma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df26d442-7f73-4a8f-84f3-853df1648777",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(chunks_txt, hf_embedding())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea5678-84b5-47d0-a140-17c3ced13638",
   "metadata": {},
   "source": [
    "##### Simple similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b9742bd-5284-4eaa-87f4-30d916eb4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca3f84e-f687-4b09-bb63-ac6ad9bd1bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='3.\\tInternet and Email Policy'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Our Internet and Email Policy aims to promote safe, responsible usage of digital communication tools that align with our values and legal obligations. Each employee is expected to understand and'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Our Internet and Email Policy is established to guide the responsible and secure use of these essential tools within our organization. We recognize their significance in daily business operations and'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Confidentiality: Reserve email for the transmission of confidential information, trade secrets, and sensitive customer data only when encryption is applied. Exercise discretion when discussing')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"email policy\"\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed53492b-21da-45e8-89e5-beeae02bd835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='3.\\tInternet and Email Policy')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can also specify `search kwargs` like `k` to limit the retrieval results.\n",
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 1})\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9966790-039f-49b4-9c98-1d3cac087bb7",
   "metadata": {},
   "source": [
    "##### MMR search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c45563-d41d-4875-95fe-a77297079380",
   "metadata": {},
   "source": [
    "MMR in vector stores is a technique used to balance the relevance and diversity of retrieved results. It selects documents that are both highly relevant to the query and minimally similar to previously selected documents. This approach helps to avoid redundancy and ensures a more comprehensive coverage of different aspects of the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1f086b6-83fb-4d6f-a4bf-31d397e2172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='3.\\tInternet and Email Policy'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Confidentiality: Reserve email for the transmission of confidential information, trade secrets, and sensitive customer data only when encryption is applied. Exercise discretion when discussing'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Review of Policy: This policy will be reviewed periodically to ensure its alignment with evolving legal requirements and best practices for maintaining a healthy and safe workplace.'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='any individual found to be in violation of this policy.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(search_type=\"mmr\")\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bfc0b4-b265-40d9-8ddf-3168967d7a1c",
   "metadata": {},
   "source": [
    "##### Similarity score threshold retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "656e6926-2829-465f-a0d3-1cf370241829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='3.\\tInternet and Email Policy'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Our Internet and Email Policy aims to promote safe, responsible usage of digital communication tools that align with our values and legal obligations. Each employee is expected to understand and'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Our Internet and Email Policy is established to guide the responsible and secure use of these essential tools within our organization. We recognize their significance in daily business operations and'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Confidentiality: Reserve email for the transmission of confidential information, trade secrets, and sensitive customer data only when encryption is applied. Exercise discretion when discussing')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.4}\n",
    ")\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce265d5c-d98e-4b9d-8836-e6bf9bc79d82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Multi-Query Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd1d36f-91ac-4c8d-8388-b6cbbd7a6764",
   "metadata": {},
   "source": [
    "Distance-based vector database retrieval represents queries in high-dimensional space and finds similar embedded documents based on \"distance\". However, retrieval results may vary with subtle changes in query wording or if the embeddings do not accurately capture the data's semantics.\n",
    "\n",
    "The `MultiQueryRetriever` addresses this by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and then takes the unique union of these results to form a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the `MultiQueryRetriever` can potentially overcome some limitations of distance-based retrieval, resulting in a richer and more diverse set of results.\n",
    "\n",
    "The following picture shows the difference between retrievers solely based on distance and the Multi-Query Retriever.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/NCZCJ26bp3uKTa0gp8Agwg/multiquery.png\" width=\"40%\" alt=\"multiquery\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de4de0e3-296e-4c22-82c1-322e114c3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8611ecf4-9374-4c68-b455-57e929ab35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf\")\n",
    "pdf_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "507a6087-9ea2-43e6-9598-620ba32f3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c8d30d5-7ec9-410e-b192-8fc9e0becfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "chunks_pdf = text_splitter(pdf_data, 500, 20)\n",
    "\n",
    "# VectorDB\n",
    "ids = vectordb.get()[\"ids\"]\n",
    "vectordb.delete(ids) # We need to delete existing embeddings from previous documents and then store current document embeddings in.\n",
    "vectordb = Chroma.from_documents(documents=chunks_pdf, embedding=hf_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f69a30f-6593-405a-b313-40d0d65b2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "query = \"What does the paper say about langchain?\"\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\"k\": 2}), \n",
    "    llm=llm() # ‚úÖ Correct: using Chat LLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee732fa2-2316-486c-a13a-b9a4af8cd1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 's8329 final', 'page_label': '5', 'total_pages': 6, 'moddate': '2023-12-31T03:52:06+00:00', 'creator': 'Microsoft Word', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'producer': 'PyPDF', 'author': 'IEEE', 'creationdate': '2023-12-31T03:50:13+00:00', 'page': 4}, page_content=\"question (Fig. 4b). \\n‚Ä¢ MindGuide Chatbot's AI response to the \\nsubsequent human message, followed by another \\nmental health question from the human (Fig. 4c). \\n‚Ä¢ MindGuide Chatbot's AI response after \\nanalyzing the latest human message (Fig. 4d). \\n \\n   s \\n                                                         (a)      (b) \\n      \\n                                                         (c)      (d)\"),\n",
       " Document(metadata={'page_label': '5', 'title': 's8329 final', 'creator': 'Microsoft Word', 'page': 4, 'creationdate': '2023-12-31T03:50:13+00:00', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'author': 'IEEE', 'total_pages': 6, 'moddate': '2023-12-31T03:52:06+00:00', 'producer': 'PyPDF'}, page_content='Augmented Generation (RAG) and incorporating embedding \\nvectors for frequently asked questions related to mental health.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'moddate': '2023-12-31T03:52:06+00:00', 'page': 1, 'total_pages': 6, 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'title': 's8329 final', 'creator': 'Microsoft Word', 'author': 'IEEE', 'page_label': '2', 'creationdate': '2023-12-31T03:50:13+00:00'}, page_content='LangChain helps us to unlock the ability to harness the \\nLLM‚Äôs immense potential in tasks such as document analysis, \\nchatbot development, code analysis, and countless other \\napplications. Whether your desire is to unlock deeper natural \\nlanguage understanding , enhance data, or circumvent \\nlanguage barriers through translation, LangChain is ready to \\nprovide the tools and programming support you need to do \\nwithout it that it is not only difficult but also fresh for you. Its'),\n",
       " Document(metadata={'page_label': '6', 'page': 5, 'moddate': '2023-12-31T03:52:06+00:00', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'producer': 'PyPDF', 'title': 's8329 final', 'creator': 'Microsoft Word', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'total_pages': 6}, page_content='[11] LangChain‚Äôs Large Language Model Chain,  \\nhttps://python.langchain.com/docs/modules/chains/foundational/llm_c\\nhain (accessed Nov. 29, 2023). \\n[12] Streamlit, https://streamlit.io/ (accessed Nov. 29, 2023).'),\n",
       " Document(metadata={'page_label': '2', 'moddate': '2023-12-31T03:52:06+00:00', 'total_pages': 6, 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'page': 1, 'producer': 'PyPDF', 'author': 'IEEE', 'creator': 'Microsoft Word', 'title': 's8329 final', 'creationdate': '2023-12-31T03:50:13+00:00'}, page_content='core functionalities encompass: \\n1. Context-Aware Capabilities: LangChain facilitates the \\ndevelopment of applications that are inherently \\ncontext-aware. This means that these applications can \\nconnect to a language model and draw from various \\nsources of context, such as prompt instructions, a few-\\nshot examples, or existing content, to ground their \\nresponses effectively. \\n2. Reasoning Abilities: LangChain equips applications \\nwith the capacity to reason effectively. By relying on a'),\n",
       " Document(metadata={'total_pages': 6, 'creator': 'Microsoft Word', 'producer': 'PyPDF', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'title': 's8329 final', 'page': 2, 'moddate': '2023-12-31T03:52:06+00:00', 'author': 'IEEE', 'page_label': '3', 'creationdate': '2023-12-31T03:50:13+00:00'}, page_content='D. Chain \\nChains [11] in LangChain refer to the combination of \\nmultiple components to achieve specific tasks. They provide \\na structured and modular approach to building language \\nmodel applications. By combining different components, you \\ncan create chains that address various u se cases and \\nrequirements. Here are some advantages of using chains: \\n‚Ä¢ Modularity: Chains allow you to break down \\ncomplex tasks into smaller, manageable \\ncomponents. Each component can be developed and')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f283237c-746b-45f0-b5b5-463a6f64c79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Generated 1 queries:\n",
      "  1. Here are three alternative queries that can help improve document retrieval:\n",
      "\n",
      "1. What is discussed in the paper regarding LangChain?\n",
      "2. Can you summarize the content related to LangChain in this paper?\n",
      "3. How does LangChain relate to the topics covered in this research paper?\n",
      "\n",
      "These revised queries use different wordings and phrasings to capture more specific information about what the user is looking for, which can help improve the accuracy of document retrieval results.\n",
      "\n",
      "‚úÖ Retrieved 1 unique documents\n",
      "1: LangChain helps us to unlock the ability to harness the \n",
      "LLM‚Äôs immense potential in tasks such as document analysis, \n",
      "chatbot development, code analys...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def create_multi_query_retriever(vectordb, llm):\n",
    "    \"\"\"Custom MultiQueryRetriever - works with your exact setup\"\"\"\n",
    "    \n",
    "    def retrieve_with_multi_query(query):\n",
    "        # Generate multiple queries using LLM\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        Generate 3 different versions of this query for better document retrieval:\n",
    "        Original: {question}\n",
    "        \n",
    "        Return 3 queries separated by \"|||\":\n",
    "        \"\"\")\n",
    "        \n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        response = chain.invoke({\"question\": query})\n",
    "        \n",
    "        # Parse queries\n",
    "        queries = [q.strip() for q in response.split(\"|||\") if q.strip()]\n",
    "        print(f\"üîç Generated {len(queries)} queries:\")\n",
    "        for i, q in enumerate(queries[:3], 1):\n",
    "            print(f\"  {i}. {q}\")\n",
    "        \n",
    "        # Retrieve documents for each query\n",
    "        all_docs = []\n",
    "        for query_variant in queries[:3]:\n",
    "            docs = vectordb.similarity_search(query_variant, k=3)\n",
    "            all_docs.extend(docs)\n",
    "        \n",
    "        # Remove duplicates and return top results\n",
    "        unique_docs = []\n",
    "        seen_sources = set()\n",
    "        for doc in all_docs:\n",
    "            source_key = f\"{doc.metadata.get('source', '')}-{doc.metadata.get('page', 0)}\"\n",
    "            if source_key not in seen_sources:\n",
    "                unique_docs.append(doc)\n",
    "                seen_sources.add(source_key)\n",
    "        \n",
    "        return unique_docs[:8]\n",
    "    \n",
    "    return retrieve_with_multi_query\n",
    "\n",
    "# ‚úÖ Use it exactly like MultiQueryRetriever\n",
    "query = \"What does the paper say about langchain?\"\n",
    "multi_retriever = create_multi_query_retriever(vectordb, llm())\n",
    "\n",
    "# Works exactly the same!\n",
    "docs = multi_retriever(query)\n",
    "print(f\"\\n‚úÖ Retrieved {len(docs)} unique documents\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"{i+1}: {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb3bb1-c843-4591-8d42-7bf89670e858",
   "metadata": {},
   "source": [
    "### Self-Querying Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea9dbb-2504-4bdb-8324-115129cf7591",
   "metadata": {},
   "source": [
    "A Self-Querying Retriever, as the name suggests, has the ability to query itself. Specifically, given a natural language query, the retriever uses a query-constructing LLM chain to generate a structured query. It then applies this structured query to its underlying vector store. This enables the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but also to extract and apply filters based on the metadata of those documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8238a796-ce37-4267-9240-da1635e8dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "#from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain_classic.chains.query_constructor.base import AttributeInfo\n",
    "from langchain_classic.retrievers.self_query.base import SelfQueryRetriever\n",
    "from lark import lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2370d15e-7e3e-4358-87e3-51dd1e6a6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"thriller\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0fdcebf-64c6-41d6-a6e0-08517d6ca62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a1e76c8-2d96-4306-8d2b-8640d1de9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(docs, hf_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50501460-cf81-467e-8c67-46e9cdbfe25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Brief summary of a movie.\"\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm(),\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a503d3bc-f91a-40fe-a2d8-7e77d4cd0826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea'),\n",
       " Document(metadata={'genre': 'thriller', 'rating': 9.9, 'year': 1979, 'director': 'Andrei Tarkovsky'}, page_content='Three men walk into the Zone, three men walk out of the Zone')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example only specifies a filter\n",
    "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a0a92d8-1218-411f-86eb-2e15c6b8effa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 results\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.exceptions import OutputParserException\n",
    "\n",
    "# Solution 2: Use proper exception handling\n",
    "try:\n",
    "    results = retriever.invoke(\"Has Greta Gerwig directed any movies about women\")\n",
    "    print(f\"Found {len(results)} results\")\n",
    "except OutputParserException as e:\n",
    "    print(f\"Output parsing error: {e}\")\n",
    "    # Fallback: try a simpler query\n",
    "    try:\n",
    "        results = retriever.invoke(\"Greta Gerwig women movies\")\n",
    "        print(f\"Fallback query returned {len(results)} results\")\n",
    "    except Exception as fallback_error:\n",
    "        print(f\"Fallback also failed: {fallback_error}\")\n",
    "except Exception as e:\n",
    "    print(f\"General error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd232fd0-9769-4f36-a397-ca3824c44397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='02a80ad5-f843-4946-8475-1b44da921d47', metadata={'rating': 8.3, 'year': 2019, 'director': 'Greta Gerwig'}, page_content='A bunch of normal-sized women are supremely wholesome and some men pine after them')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7b44f36-3ed0-4331-9800-4354c59c4f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'year': 1993, 'rating': 7.7, 'genre': 'science fiction'}, page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example specifies a composite filter\n",
    "retriever.invoke(\"What's a highly rated (above 8.5) science fiction film?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eabe13f-6790-4daa-8012-c5a350b6f83e",
   "metadata": {},
   "source": [
    "### Parent Document Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9f8e8-03c9-429c-9894-e54018378b0e",
   "metadata": {},
   "source": [
    "When splitting documents for retrieval, there are often conflicting desires:\n",
    "\n",
    "1. You may want to have small documents so that their embeddings can most accurately reflect their meaning. If the documents are too long, the embeddings can lose meaning.\n",
    "2. You want to have long enough documents so that the context of each chunk is retained.\n",
    "\n",
    "The `ParentDocumentRetriever` strikes that balance by splitting and storing small chunks of data. During retrieval, it first fetches the small chunks but then looks up the parent IDs for those chunks and returns those larger documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec056ca0-861e-4069-a183-58c466cab8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers import ParentDocumentRetriever\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_core.stores import InMemoryStore  # ‚úÖ CORRECT BaseStore\n",
    "#from langchain_community.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "853c6fae-775a-4788-b97e-8cd60b7de4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set two splitters. One is with big chunk size (parent) and one is with small chunk size (child)\n",
    "parent_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100, separator='\\n')\n",
    "child_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=30, separator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c884b32-1de2-4674-8d43-7f4719b7a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    collection_name=\"split_parents\", embedding_function=hf_embedding()\n",
    ")\n",
    "#vectordb = Chroma.from_documents(documents=chunks_pdf, embedding=watsonx_embedding())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67c1d282-e192-4b40-9884-ec5fbb400f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60088d7f-d405-487a-83d1-dc02009329e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectordb,  # Your existing Chroma\n",
    "    docstore=store,        # ‚úÖ InMemoryStore (KeyValue)\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "421647d0-ea3d-4a88-9b1e-0d7764b354f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 223, which is longer than the specified 200\n",
      "Created a chunk of size 274, which is longer than the specified 200\n",
      "Created a chunk of size 262, which is longer than the specified 200\n",
      "Created a chunk of size 282, which is longer than the specified 200\n",
      "Created a chunk of size 262, which is longer than the specified 200\n",
      "Created a chunk of size 270, which is longer than the specified 200\n",
      "Created a chunk of size 224, which is longer than the specified 200\n",
      "Created a chunk of size 325, which is longer than the specified 200\n",
      "Created a chunk of size 300, which is longer than the specified 200\n",
      "Created a chunk of size 216, which is longer than the specified 200\n",
      "Created a chunk of size 242, which is longer than the specified 200\n",
      "Created a chunk of size 235, which is longer than the specified 200\n",
      "Created a chunk of size 300, which is longer than the specified 200\n",
      "Created a chunk of size 294, which is longer than the specified 200\n",
      "Created a chunk of size 234, which is longer than the specified 200\n",
      "Created a chunk of size 321, which is longer than the specified 200\n",
      "Created a chunk of size 256, which is longer than the specified 200\n",
      "Created a chunk of size 249, which is longer than the specified 200\n",
      "Created a chunk of size 211, which is longer than the specified 200\n",
      "Created a chunk of size 267, which is longer than the specified 200\n",
      "Created a chunk of size 206, which is longer than the specified 200\n",
      "Created a chunk of size 694, which is longer than the specified 200\n",
      "Created a chunk of size 323, which is longer than the specified 200\n",
      "Created a chunk of size 326, which is longer than the specified 200\n",
      "Created a chunk of size 296, which is longer than the specified 200\n",
      "Created a chunk of size 233, which is longer than the specified 200\n",
      "Created a chunk of size 421, which is longer than the specified 200\n",
      "Created a chunk of size 243, which is longer than the specified 200\n",
      "Created a chunk of size 260, which is longer than the specified 200\n",
      "Created a chunk of size 229, which is longer than the specified 200\n",
      "Created a chunk of size 290, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "retriever.add_documents(txt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc073a85-c7db-49fc-b6fd-4392313e51a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(store.yield_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "535c8754-a536-4906-a707-e30e55003c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = vectordb.similarity_search(\"smoking policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "addf8224-b69c-4c50-825f-07823d1c6eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.\tSmoking Policy\n"
     ]
    }
   ],
   "source": [
    "print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d7b2ed9-b753-40c5-82ae-4e2ce461963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices.\n",
      "5.\tSmoking Policy\n",
      "Policy Purpose: The Smoking Policy has been established to provide clear guidance and expectations concerning smoking on company premises. This policy is in place to ensure a safe and healthy environment for all employees, visitors, and the general public.\n",
      "Designated Smoking Areas: Smoking is only permitted in designated smoking areas, as marked by appropriate signage. These areas have been chosen to minimize exposure to secondhand smoke and to maintain the overall cleanliness of the premises.\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"smoking policy\")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba4b9a-ed48-4125-baa2-00d740eafa22",
   "metadata": {},
   "source": [
    "### Retrieve Top 2 Results Using a Vector Store-Backed Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff160220-900a-4175-a275-d81215cf20f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='99d767bf-3604-4f4e-8d06-b57134aedfa1', metadata={'source': 'companypolicies.txt'}, page_content='6.\\tDrug and Alcohol Policy'),\n",
       " Document(id='90a643f5-fa43-49ce-a63f-a546de8e93f8', metadata={'source': 'companypolicies.txt'}, page_content='Policy Objective: The Drug and Alcohol Policy is established to establish clear expectations and guidelines for the responsible use of drugs and alcohol within the organization. This policy aims to')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(documents=chunks_txt, embedding=hf_embedding())\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
    "query = \"Drinking Policy\"\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643c5af-4999-4f39-a77a-461bd051d032",
   "metadata": {},
   "source": [
    "### Self-Querying Retriever for a Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78397d44-f7d9-4c73-a5a9-9c4270f84e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5735a942-35aa-4370-ae52-20395ba50f95', metadata={'year': 2006, 'rating': 8.6, 'director': 'Satoshi Kon'}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea'),\n",
       " Document(id='d1392d4a-b217-49ce-b69b-b5e31da815a0', metadata={'source': 'companypolicies.txt'}, page_content='online activity or potential security breaches.'),\n",
       " Document(id='64d4e58a-3552-44cb-8a36-8c18f47cb0b6', metadata={'source': 'companypolicies.txt'}, page_content='concerns or suspicious activities related to your mobile device.'),\n",
       " Document(id='0cc9ab8e-cd62-4516-97df-5d89233c5762', metadata={'director': 'Christopher Nolan', 'rating': 8.2, 'year': 2010}, page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm(),\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")\n",
    "\n",
    "retriever.invoke(\n",
    "    \"Name the best mystry movie.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ebf0c-0ee3-4306-af59-0228a917459a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
